import asyncio
import time
import logging
import statistics
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from datetime import datetime
from zoneinfo import ZoneInfo

logger = logging.getLogger(__name__)

BR_TIMEZONE = ZoneInfo("America/Sao_Paulo")

@dataclass
class StatsContainer:
    """
    Um contêiner de dados robusto e otimizado para armazenar e calcular métricas
    de desempenho, com timestamps formatados e insights de paralelização.
    """
    # --- Identificação e Tempo ---
    id: str
    max_tpm_limit: int = 0
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    # --- Contadores de Requisição ---
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    error_type_counts: Counter = field(default_factory=Counter)
    total_retry_count: int = 0

    # --- Contadores de Tokens e Custo ---
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    total_cached_tokens: int = 0
    total_cost: float = 0.0

    # --- Rastreamento de Latência ---
    api_response_times: List[float] = field(default_factory=list)

    # --- Rastreamento de Concorrência ---
    current_concurrent_requests: int = 0
    concurrent_peak: int = 0

    # --- Métricas de Rate Limiter ---
    api_rate_limits_detected: int = 0
    proactive_pauses: int = 0
    total_proactive_wait_time: float = 0.0
    peak_tpm: int = 0

    # --- Propriedades Calculadas ---
    @property
    def total_tokens(self) -> int:
        return self.total_input_tokens + self.total_output_tokens
        
    @property
    def processing_time(self) -> float:
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

    @property
    def total_api_time(self) -> float:
        return sum(self.api_response_times)

    @property
    def parallelization_gain_seconds(self) -> float:
        processing_time = self.processing_time
        if processing_time > 0 and self.total_api_time > processing_time:
            return self.total_api_time - processing_time
        return 0.0

    @property
    def parallelization_gain_percent(self) -> float:
        if self.total_api_time > 0:
            return (self.parallelization_gain_seconds / self.total_api_time) * 100
        return 0.0
        
    @property
    def min_api_latency(self) -> float:
        return min(self.api_response_times) if self.api_response_times else 0

    @property
    def max_api_latency(self) -> float:
        return max(self.api_response_times) if self.api_response_times else 0

    @property
    def avg_api_latency(self) -> float:
        return statistics.mean(self.api_response_times) if self.api_response_times else 0

    @property
    def requests_per_second(self) -> float:
        processing_time = self.processing_time
        if processing_time > 0:
            return self.total_requests / processing_time
        return 0.0

    # --- INÍCIO DA CORREÇÃO ---
    # Métodos de formatação e apresentação do relatório.
    
    @staticmethod
    def _format_timestamp(timestamp: Optional[float]) -> str:
        if not timestamp: return "N/A"
        dt_object = datetime.fromtimestamp(timestamp, tz=BR_TIMEZONE)
        return dt_object.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]

    @property
    def start_time_formatted(self) -> str:
        return self._format_timestamp(self.start_time)

    @property
    def end_time_formatted(self) -> str:
        return self._format_timestamp(self.end_time)

    def get_report(self) -> str:
        """Formata as estatísticas em um relatório legível e rico em insights."""
        title = f" RELATÓRIO DE PERFORMANCE: {self.id.upper()} "
        header = f"\n{title.center(80, '=')}"

        summary = (
            f"📊 RESUMO GERAL:\n"
            f"   - Período de Execução: {self.start_time_formatted} -> {self.end_time_formatted}\n"
            f"   - Duração Total: {self.processing_time:.3f}s\n"
            f"   - Requisições: {self.total_requests} (✅ {self.successful_requests} Sucesso | ❌ {self.failed_requests} Falhas)\n"
            f"   - Custo Total Estimado: ${self.total_cost:.4f}\n"
            f"   - Total de Tokens: {self.total_tokens:,} (Entrada: {self.total_input_tokens:,}, Saída: {self.total_output_tokens:,})"
        )

        parallelization = ""
        if self.total_requests > 1:
            parallelization = (
                f"\n🚀 EFICIÊNCIA DA PARALELIZAÇÃO:\n"
                f"   - Tempo Total de API (Sequencial): {self.total_api_time:.3f}s\n"
                f"   - Ganho com Paralelização: {self.parallelization_gain_seconds:.3f}s ({self.parallelization_gain_percent:.1f}% de economia de tempo)\n"
                f"   - Pico de Concorrência: {self.concurrent_peak} requisições simultâneas"
            )

        tpm_usage_percent = (self.peak_tpm / self.max_tpm_limit * 100) if self.max_tpm_limit > 0 else 0
        performance = (
            f"\n⏱️ PERFORMANCE E LATÊNCIA:\n"
            f"   - Vazão (Throughput): {self.requests_per_second:.2f} reqs/s\n"
            f"   - Latência da API (média | min | max): {self.avg_api_latency:.3f}s | {self.min_api_latency:.3f}s | {self.max_api_latency:.3f}s\n"
            f"   - Pico de TPM: {self.peak_tpm:,} ({tpm_usage_percent:.1f}% do limite de {self.max_tpm_limit:,})\n"
            f"   - Pausas Proativas: {self.proactive_pauses} (totalizando {self.total_proactive_wait_time:.2f}s)"
        )
        
        errors = ""
        if self.failed_requests > 0:
            error_details = ', '.join([f"{k}: {v}" for k, v in self.error_type_counts.items()])
            errors = (
                f"\n⚠️ ANÁLISE DE ERROS:\n"
                f"   - Total de Falhas: {self.failed_requests}\n"
                f"   - Tipos de Erro: {error_details}\n"
                f"   - Rate Limits da API Detectados: {self.api_rate_limits_detected}"
            )

        footer = "=" * 80
        return "\n".join(filter(None, [header, summary, parallelization, performance, errors, footer]))

# --- FIM DA CORREÇÃO ---

class StatsManager:
    def __init__(self, max_tpm: int):
        self.max_tpm = max_tpm
        self._global_stats = StatsContainer(id="global", max_tpm_limit=self.max_tpm)
        self._batch_stats: Dict[str, StatsContainer] = {}
        self._lock = asyncio.Lock()
        logger.info("StatsManager inicializado e pronto para gerar insights.")

    async def _update_stats(self, stats: StatsContainer, **kwargs):
        stats.total_requests += 1
        if kwargs.get('success', False):
            stats.successful_requests += 1
            stats.total_cost += kwargs.get('cost', 0.0)
            stats.total_input_tokens += kwargs.get('input_tokens', 0)
            stats.total_output_tokens += kwargs.get('output_tokens', 0)
            stats.total_cached_tokens += kwargs.get('cached_tokens', 0)
        else:
            stats.failed_requests += 1
            stats.error_type_counts[kwargs.get('error_type', 'UnknownError')] += 1
        
        if (api_time := kwargs.get('api_response_time', 0.0)) > 0:
            stats.api_response_times.append(api_time)
        stats.total_retry_count += kwargs.get('retry_count', 0)

    async def record_request(self, batch_id: Optional[str] = None, **kwargs):
        async with self._lock:
            await self._update_stats(self._global_stats, **kwargs)
            if batch_id and batch_id in self._batch_stats:
                await self._update_stats(self._batch_stats[batch_id], **kwargs)

    async def record_rate_limiter_event(self, event: Dict[str, Any], batch_id: Optional[str] = None):
        event_type = event.get('event_type')
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                if event_type == 'proactive_pause':
                    stats.proactive_pauses += 1
                    stats.total_proactive_wait_time += event.get('wait_time', 0.0)
                elif event_type == 'api_rate_limit_detected':
                     stats.api_rate_limits_detected += 1
                elif event_type == 'token_usage_update':
                    current_tpm = event.get('current_tpm', 0)
                    if current_tpm > stats.peak_tpm:
                        stats.peak_tpm = current_tpm
    
    async def record_concurrent_start(self, batch_id: Optional[str] = None):
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests += 1
                if stats.current_concurrent_requests > stats.concurrent_peak:
                    stats.concurrent_peak = stats.current_concurrent_requests

    async def record_concurrent_end(self, batch_id: Optional[str] = None):
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests = max(0, stats.current_concurrent_requests - 1)

    def _get_relevant_containers(self, batch_id: Optional[str]) -> List[StatsContainer]:
        containers = [self._global_stats]
        if batch_id and batch_id in self._batch_stats:
            containers.append(self._batch_stats[batch_id])
        return containers

    def start_batch(self, batch_id: str):
        if batch_id in self._batch_stats:
            logger.warning(f"Batch com ID '{batch_id}' já existe. Sobrescrevendo estatísticas.")
        self._batch_stats[batch_id] = StatsContainer(id=batch_id, max_tpm_limit=self.max_tpm)
        logger.info(f"Lote de estatísticas '{batch_id}' iniciado.")

    def end_batch(self, batch_id: str) -> Optional[StatsContainer]:
        if batch_stats := self._batch_stats.get(batch_id):
            batch_stats.end_time = time.time()
            return batch_stats
        return None

    def get_global_stats(self) -> StatsContainer:
        return self._global_stats

    # --- INÍCIO DA CORREÇÃO ---
    # Métodos públicos para obter os relatórios formatados.

    def get_batch_report(self, batch_id: str) -> Optional[str]:
        """Gera e retorna um relatório formatado para um lote específico."""
        if batch_stats := self._batch_stats.get(batch_id):
            return batch_stats.get_report()
        logger.warning(f"Nenhuma estatística encontrada para o batch ID '{batch_id}'.")
        return None

    def get_global_report(self) -> str:
        """Gera e retorna um relatório formatado para as estatísticas globais."""
        self._global_stats.end_time = time.time() # Garante que o tempo de processamento global esteja atualizado
        return self._global_stats.get_report()
    # --- FIM DA CORREÇÃO ---
